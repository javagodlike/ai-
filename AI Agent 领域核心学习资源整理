# AI Agent 领域核心学习资源整理

根据搜索结果和当前业界趋势，我为您整理了关于AI Agent的系统学习资源：

## 📘 核心白皮书与理论文献

### **1. C3 AI企业级Agent白皮书** ⭐⭐⭐⭐⭐
- **标题**：AI Agents for Enterprise-Grade Agentic Process Automation
- **链接**：https://c3.ai/white-paper-ai-agents-for-enterprise-grade-agentic-process-automation/
- **核心内容**：
  - AI Agent的定义与工作原理
  - 企业级Agent的实现要求
  - Agentic Process Automation（代理流程自动化）
  - 4个企业部署案例研究<sub index="1" url="https://c3.ai/white-paper-ai-agents-for-enterprise-grade-agentic-process-automation/" title="White Paper: AI Agents for Enterprise-Grade ..." snippet="# White Paper: AI Agents for Enterprise-Grade Agentic Process AutomationAI agents represent a paradigm shift, moving beyond simple rule-based task execution to complex, goal-oriented decision-making. AI agents can receive an abstract goal and input, formulate a plan to achieve that goal, and then use a set of &ldquo;tools&rdquo; to execute that plan. This white paper seeks to define AI agents, explain the critical components of an AI agent, and present a framework for the successful, timely, and cost-effective implementation of AI agents in the enterprise. We additionally address the emerging new concept of C3 AI Agentic Process Automation with advanced AI agent-assisted reasoning to unlock outsized economic value at scale. C3 AI has invested deeply in building an agentic architecture purpose-built for the complexity of enterprise environments.In this white paper, you will learn about:* AI agents and how they work * Requirements for AI agents for high-value, enterprise use cases * Transforming enterprise work with agentic process automation * Four case studies from C3 AI highlighting AI agents and agentic process automation in enterprise deployments "></sub>

### **2. Kaggle Agent白皮书**
- **作者**：Julia Wiesinger, Patrick Marlow, Vladimir Vuskovic
- **链接**：https://www.kaggle.com/whitepaper-agents
- **核心内容**：
  - Agent如何使用外部工具
  - 推理、逻辑与信息访问的结合
  - Agent与生成式AI模型的关系<sub index="4" url="https://www.kaggle.com/whitepaper-agents" title="Agents" snippet="Humans are fantastic at messy pattern recognition tasks. However, they often rely on tools - like books, Google Search, or a calculator - to supplement their prior knowledge before arriving at a conclusion. Just like humans, Generative AI models can be trained to use tools to access real-time information or suggest a real-world action. For example, a model can leverage a database retrieval tool to access specific information, like a customer's purchase history, so it can generate tailored shopping recommendations. Alternatively, based on a user's query, a model can make various API calls to send an email response to a colleague or complete a financial transaction on your behalf. To do so, the model must not only have access to a set of external tools, it needs the ability to plan and execute any task in a self-directed fashion. This combination of reasoning, logic, and access to external information that are all connected to a Generative AI model invokes the concept of an agent, or a program that extends beyond the standalone capabilities of a Generative AI model. This whitepaper dives into all these and associated aspects in more detail.Authors: Julia Wiesinger, Patrick Marlow and Vladimir VuskovicIntroductionRead the whitepaper below"></sub>

### **3. 中文深度解析文章**
- **标题**：AI Agent架构白皮书（中文翻译版）
- **链接**：https://arthurchiao.art/blog/ai-agent-white-paper-zh/
- **核心内容**：详细讲解Agent的三层架构和工作原理<sub index="2" url="https://arthurchiao.art/blog/ai-agent-white-paper-zh/" title="[译] AI Agent（智能体）技术白皮书（Google，2024）" snippet="例如，结合用户信息和获取天气数据的 tool，Agent 可以为用户提供旅行建议。有了工具，Agent 可以访问和处理现实世界的信息，这使它们能够支撑更专业的系统，如检索增强生成（RAG），显著扩展了 Agent 的能力。### 2.3.3 编排层（orchestration）编排层描述了一个**循环** 过程：Agent 如何接收信息，如何进行内部推理，如何使用推理来结果来指导其下一步行动或决策。* 一般来说，这个循环会持续进行，直到 Agent 达到其目标或触发停止条件。 * 编排层的复杂性跟 Agent 及其执行的任务直接相关，可能差异很大。 例如，一些编排就是简单的计算和决策规则，而其他的可能包含链式逻辑、额外的机器学习算法或其他概率推理技术。 我们将在认知架构部分更详细地讨论 Agent 编排层的详细实现。## 2.4 Agent 与 model 的区别为了更清楚地理解 Agent 和模型之间的区别，这里整理个表格，|  模型   |                      Agent                       |                                               ||-------|--------------------------------------------------|-----------------------------------------------|| 知识范围  | 知识仅限于其 训练数据。                                     | 通过工具连接外部系统，能够在模型自带的知识之外，实时、动态 扩展知识。           || 状态与记忆 | 无状态，每次推理都跟上一次没关系，除非在外部给模型加上会话历史或上下文管理能力。         | 有状态，自动管理会话历史，根据编排自主决策进行多轮推理。                  || 原生工具  | 无。                                               | 有，自带工具和对工具的支持能力。                              || 原生逻辑层 | 无。需要借助提示词工程或使用推理框架（CoT、ReAct 等）来形成复杂提示，指导模型进行预测。 | 有，原生认知架构，内置 CoT、ReAct 等推理框架或 LangChain 等编排框架。 |# 3 认知架构：Agent 是如何工作的## 3.1 类比：厨师做菜想象厨房中一群忙碌的厨师。他们的职责是根据顾客的菜单，为顾客烹制相应的菜品。这就涉及到我们前面提到的**&ldquo;规划 &mdash;&mdash; 执行 &mdash;&mdash; 调整&rdquo;** 循环。具体来说，厨师们需要执行以下步骤，* 收集信息（输入）：顾客点的菜，后厨现有的食材等等； * 推理（思考）：根据收集到的信息，判断可以做哪些菜； * 做菜（行动）：包括切菜、加调料、烹炒等等。 在以上每个阶段，厨师都根据需要进行调整 &mdash;&mdash; 例如某些食材不够用了，或者顾客反馈好吃或难吃了 &mdash;&mdash; 进而不断完善他们的计划。这个**信息接收、规划、执行和调整** （information intake, planning,executing, and adjusting）的循环描述的就是一个**厨师用来实现其目标的特定认知架构** 。## 3.2 Agent 推理框架跟以上厨师类似，Agent 也可以使用认知架构处理信息、做出决策，并根据前一轮的输出调整下一个行动，如此循环迭代来实现其最终目标。* 在 Agent 中，认知架构的核心是编排层，负责维护记忆、状态、推理和规划  （memory, state, reasoning and planning）。* 它使用快速发展的提示词工程及相关框架  （prompt engineering and associated frameworks）来指导推理和规划  ，使 Agent 能够更有效地与环境互动并完成任务。在写作本文时，有下面几种流行的推理框架和推理技术。### 3.2.1 ReAct为语言模型提供了一个思考过程策略。已经证明 ReAct 优于几个 SOTA 基线，提高了 LLM 的人机交互性和可信度。### 3.2.2 Chain-of-Thought (CoT)通过中间步骤实现推理能力。CoT 有各种子技术，包括自我一致性、主动提示和多模态 CoT，适合不同的场景。### 3.2.3 Tree-of-Thoughts (ToT)非常适合探索或战略前瞻任务。概括了链式思考提示，并允许模型探索各种思考链，作为使用语言模型解决问题的中间步骤。## 3.3 ReAct 例子Agent 可以使用以上一种或多种推理技术，给特定的用户请求确定下一个最佳行动。 例如，使用 ReAct 的例子，* 用户向 Agent 发送查询。 * Agent 开始 ReAct sequence。 * Agent 提示模型，要求其生成下一个 ReAct 步骤及其相应的输出：  * 问题：提示词 + 用户输入的问题 * 思考：模型的想法：下一步应该做什么 * 行动：模型的决策：下一步要采取什么行动。这里就是可以引入工具的地方， 例如，行动可以是 [Flights, Search, Code, None]* 行动的输入：模型决定是否要向工具提供输入，如果要提供，还要确定提供哪些输入 * 观察：行动/行动输入序列的结果。根据需要，这个思考/行动/行动输入/观察（thought / action / action input / observation* 最终答案：模型返回对原始用户查询的最终答案。"></sub>

## 🏗️ Agent核心架构与框架

### **Agent三层架构**<sub index="2" url="https://arthurchiao.art/blog/ai-agent-white-paper-zh/" title="[译] AI Agent（智能体）技术白皮书（Google，2024）" snippet="例如，结合用户信息和获取天气数据的 tool，Agent 可以为用户提供旅行建议。有了工具，Agent 可以访问和处理现实世界的信息，这使它们能够支撑更专业的系统，如检索增强生成（RAG），显著扩展了 Agent 的能力。### 2.3.3 编排层（orchestration）编排层描述了一个**循环** 过程：Agent 如何接收信息，如何进行内部推理，如何使用推理来结果来指导其下一步行动或决策。* 一般来说，这个循环会持续进行，直到 Agent 达到其目标或触发停止条件。 * 编排层的复杂性跟 Agent 及其执行的任务直接相关，可能差异很大。 例如，一些编排就是简单的计算和决策规则，而其他的可能包含链式逻辑、额外的机器学习算法或其他概率推理技术。 我们将在认知架构部分更详细地讨论 Agent 编排层的详细实现。## 2.4 Agent 与 model 的区别为了更清楚地理解 Agent 和模型之间的区别，这里整理个表格，|  模型   |                      Agent                       |                                               ||-------|--------------------------------------------------|-----------------------------------------------|| 知识范围  | 知识仅限于其 训练数据。                                     | 通过工具连接外部系统，能够在模型自带的知识之外，实时、动态 扩展知识。           || 状态与记忆 | 无状态，每次推理都跟上一次没关系，除非在外部给模型加上会话历史或上下文管理能力。         | 有状态，自动管理会话历史，根据编排自主决策进行多轮推理。                  || 原生工具  | 无。                                               | 有，自带工具和对工具的支持能力。                              || 原生逻辑层 | 无。需要借助提示词工程或使用推理框架（CoT、ReAct 等）来形成复杂提示，指导模型进行预测。 | 有，原生认知架构，内置 CoT、ReAct 等推理框架或 LangChain 等编排框架。 |# 3 认知架构：Agent 是如何工作的## 3.1 类比：厨师做菜想象厨房中一群忙碌的厨师。他们的职责是根据顾客的菜单，为顾客烹制相应的菜品。这就涉及到我们前面提到的**&ldquo;规划 &mdash;&mdash; 执行 &mdash;&mdash; 调整&rdquo;** 循环。具体来说，厨师们需要执行以下步骤，* 收集信息（输入）：顾客点的菜，后厨现有的食材等等； * 推理（思考）：根据收集到的信息，判断可以做哪些菜； * 做菜（行动）：包括切菜、加调料、烹炒等等。 在以上每个阶段，厨师都根据需要进行调整 &mdash;&mdash; 例如某些食材不够用了，或者顾客反馈好吃或难吃了 &mdash;&mdash; 进而不断完善他们的计划。这个**信息接收、规划、执行和调整** （information intake, planning,executing, and adjusting）的循环描述的就是一个**厨师用来实现其目标的特定认知架构** 。## 3.2 Agent 推理框架跟以上厨师类似，Agent 也可以使用认知架构处理信息、做出决策，并根据前一轮的输出调整下一个行动，如此循环迭代来实现其最终目标。* 在 Agent 中，认知架构的核心是编排层，负责维护记忆、状态、推理和规划  （memory, state, reasoning and planning）。* 它使用快速发展的提示词工程及相关框架  （prompt engineering and associated frameworks）来指导推理和规划  ，使 Agent 能够更有效地与环境互动并完成任务。在写作本文时，有下面几种流行的推理框架和推理技术。### 3.2.1 ReAct为语言模型提供了一个思考过程策略。已经证明 ReAct 优于几个 SOTA 基线，提高了 LLM 的人机交互性和可信度。### 3.2.2 Chain-of-Thought (CoT)通过中间步骤实现推理能力。CoT 有各种子技术，包括自我一致性、主动提示和多模态 CoT，适合不同的场景。### 3.2.3 Tree-of-Thoughts (ToT)非常适合探索或战略前瞻任务。概括了链式思考提示，并允许模型探索各种思考链，作为使用语言模型解决问题的中间步骤。## 3.3 ReAct 例子Agent 可以使用以上一种或多种推理技术，给特定的用户请求确定下一个最佳行动。 例如，使用 ReAct 的例子，* 用户向 Agent 发送查询。 * Agent 开始 ReAct sequence。 * Agent 提示模型，要求其生成下一个 ReAct 步骤及其相应的输出：  * 问题：提示词 + 用户输入的问题 * 思考：模型的想法：下一步应该做什么 * 行动：模型的决策：下一步要采取什么行动。这里就是可以引入工具的地方， 例如，行动可以是 [Flights, Search, Code, None]* 行动的输入：模型决定是否要向工具提供输入，如果要提供，还要确定提供哪些输入 * 观察：行动/行动输入序列的结果。根据需要，这个思考/行动/行动输入/观察（thought / action / action input / observation* 最终答案：模型返回对原始用户查询的最终答案。"></sub>

#### **第一层：模型层（Model）**
- 知识范围：通过工具连接外部系统，实时动态扩展知识
- 状态管理：自动管理会话历史
- 原生工具支持

#### **第二层：工具层（Tools）**
- 检索增强生成（RAG）
- 数据库访问
- API调用能力
- 实时信息获取

#### **第三层：编排层（Orchestration）**
- 循环推理过程
- 决策逻辑
- 任务规划与执行

### **三大主流推理框架**<sub index="2" url="https://arthurchiao.art/blog/ai-agent-white-paper-zh/" title="[译] AI Agent（智能体）技术白皮书（Google，2024）" snippet="例如，结合用户信息和获取天气数据的 tool，Agent 可以为用户提供旅行建议。有了工具，Agent 可以访问和处理现实世界的信息，这使它们能够支撑更专业的系统，如检索增强生成（RAG），显著扩展了 Agent 的能力。### 2.3.3 编排层（orchestration）编排层描述了一个**循环** 过程：Agent 如何接收信息，如何进行内部推理，如何使用推理来结果来指导其下一步行动或决策。* 一般来说，这个循环会持续进行，直到 Agent 达到其目标或触发停止条件。 * 编排层的复杂性跟 Agent 及其执行的任务直接相关，可能差异很大。 例如，一些编排就是简单的计算和决策规则，而其他的可能包含链式逻辑、额外的机器学习算法或其他概率推理技术。 我们将在认知架构部分更详细地讨论 Agent 编排层的详细实现。## 2.4 Agent 与 model 的区别为了更清楚地理解 Agent 和模型之间的区别，这里整理个表格，|  模型   |                      Agent                       |                                               ||-------|--------------------------------------------------|-----------------------------------------------|| 知识范围  | 知识仅限于其 训练数据。                                     | 通过工具连接外部系统，能够在模型自带的知识之外，实时、动态 扩展知识。           || 状态与记忆 | 无状态，每次推理都跟上一次没关系，除非在外部给模型加上会话历史或上下文管理能力。         | 有状态，自动管理会话历史，根据编排自主决策进行多轮推理。                  || 原生工具  | 无。                                               | 有，自带工具和对工具的支持能力。                              || 原生逻辑层 | 无。需要借助提示词工程或使用推理框架（CoT、ReAct 等）来形成复杂提示，指导模型进行预测。 | 有，原生认知架构，内置 CoT、ReAct 等推理框架或 LangChain 等编排框架。 |# 3 认知架构：Agent 是如何工作的## 3.1 类比：厨师做菜想象厨房中一群忙碌的厨师。他们的职责是根据顾客的菜单，为顾客烹制相应的菜品。这就涉及到我们前面提到的**&ldquo;规划 &mdash;&mdash; 执行 &mdash;&mdash; 调整&rdquo;** 循环。具体来说，厨师们需要执行以下步骤，* 收集信息（输入）：顾客点的菜，后厨现有的食材等等； * 推理（思考）：根据收集到的信息，判断可以做哪些菜； * 做菜（行动）：包括切菜、加调料、烹炒等等。 在以上每个阶段，厨师都根据需要进行调整 &mdash;&mdash; 例如某些食材不够用了，或者顾客反馈好吃或难吃了 &mdash;&mdash; 进而不断完善他们的计划。这个**信息接收、规划、执行和调整** （information intake, planning,executing, and adjusting）的循环描述的就是一个**厨师用来实现其目标的特定认知架构** 。## 3.2 Agent 推理框架跟以上厨师类似，Agent 也可以使用认知架构处理信息、做出决策，并根据前一轮的输出调整下一个行动，如此循环迭代来实现其最终目标。* 在 Agent 中，认知架构的核心是编排层，负责维护记忆、状态、推理和规划  （memory, state, reasoning and planning）。* 它使用快速发展的提示词工程及相关框架  （prompt engineering and associated frameworks）来指导推理和规划  ，使 Agent 能够更有效地与环境互动并完成任务。在写作本文时，有下面几种流行的推理框架和推理技术。### 3.2.1 ReAct为语言模型提供了一个思考过程策略。已经证明 ReAct 优于几个 SOTA 基线，提高了 LLM 的人机交互性和可信度。### 3.2.2 Chain-of-Thought (CoT)通过中间步骤实现推理能力。CoT 有各种子技术，包括自我一致性、主动提示和多模态 CoT，适合不同的场景。### 3.2.3 Tree-of-Thoughts (ToT)非常适合探索或战略前瞻任务。概括了链式思考提示，并允许模型探索各种思考链，作为使用语言模型解决问题的中间步骤。## 3.3 ReAct 例子Agent 可以使用以上一种或多种推理技术，给特定的用户请求确定下一个最佳行动。 例如，使用 ReAct 的例子，* 用户向 Agent 发送查询。 * Agent 开始 ReAct sequence。 * Agent 提示模型，要求其生成下一个 ReAct 步骤及其相应的输出：  * 问题：提示词 + 用户输入的问题 * 思考：模型的想法：下一步应该做什么 * 行动：模型的决策：下一步要采取什么行动。这里就是可以引入工具的地方， 例如，行动可以是 [Flights, Search, Code, None]* 行动的输入：模型决定是否要向工具提供输入，如果要提供，还要确定提供哪些输入 * 观察：行动/行动输入序列的结果。根据需要，这个思考/行动/行动输入/观察（thought / action / action input / observation* 最终答案：模型返回对原始用户查询的最终答案。"></sub>

#### **1. ReAct（Reasoning + Acting）**
- **核心论文**：https://arxiv.org/abs/2210.03629 <sub index="5" url="https://arxiv.org/abs/2210.03629" title="Synergizing Reasoning and Acting in Language Models" snippet=""></sub>
- **工作流程**：
  - 问题理解 → 思考（Thought）
  - 决策行动（Action）→ 行动输入
  - 观察结果（Observation）→ 最终答案
- **优势**：提高LLM的人机交互性和可信度<sub index="2" url="https://arthurchiao.art/blog/ai-agent-white-paper-zh/" title="[译] AI Agent（智能体）技术白皮书（Google，2024）" snippet="例如，结合用户信息和获取天气数据的 tool，Agent 可以为用户提供旅行建议。有了工具，Agent 可以访问和处理现实世界的信息，这使它们能够支撑更专业的系统，如检索增强生成（RAG），显著扩展了 Agent 的能力。### 2.3.3 编排层（orchestration）编排层描述了一个**循环** 过程：Agent 如何接收信息，如何进行内部推理，如何使用推理来结果来指导其下一步行动或决策。* 一般来说，这个循环会持续进行，直到 Agent 达到其目标或触发停止条件。 * 编排层的复杂性跟 Agent 及其执行的任务直接相关，可能差异很大。 例如，一些编排就是简单的计算和决策规则，而其他的可能包含链式逻辑、额外的机器学习算法或其他概率推理技术。 我们将在认知架构部分更详细地讨论 Agent 编排层的详细实现。## 2.4 Agent 与 model 的区别为了更清楚地理解 Agent 和模型之间的区别，这里整理个表格，|  模型   |                      Agent                       |                                               ||-------|--------------------------------------------------|-----------------------------------------------|| 知识范围  | 知识仅限于其 训练数据。                                     | 通过工具连接外部系统，能够在模型自带的知识之外，实时、动态 扩展知识。           || 状态与记忆 | 无状态，每次推理都跟上一次没关系，除非在外部给模型加上会话历史或上下文管理能力。         | 有状态，自动管理会话历史，根据编排自主决策进行多轮推理。                  || 原生工具  | 无。                                               | 有，自带工具和对工具的支持能力。                              || 原生逻辑层 | 无。需要借助提示词工程或使用推理框架（CoT、ReAct 等）来形成复杂提示，指导模型进行预测。 | 有，原生认知架构，内置 CoT、ReAct 等推理框架或 LangChain 等编排框架。 |# 3 认知架构：Agent 是如何工作的## 3.1 类比：厨师做菜想象厨房中一群忙碌的厨师。他们的职责是根据顾客的菜单，为顾客烹制相应的菜品。这就涉及到我们前面提到的**&ldquo;规划 &mdash;&mdash; 执行 &mdash;&mdash; 调整&rdquo;** 循环。具体来说，厨师们需要执行以下步骤，* 收集信息（输入）：顾客点的菜，后厨现有的食材等等； * 推理（思考）：根据收集到的信息，判断可以做哪些菜； * 做菜（行动）：包括切菜、加调料、烹炒等等。 在以上每个阶段，厨师都根据需要进行调整 &mdash;&mdash; 例如某些食材不够用了，或者顾客反馈好吃或难吃了 &mdash;&mdash; 进而不断完善他们的计划。这个**信息接收、规划、执行和调整** （information intake, planning,executing, and adjusting）的循环描述的就是一个**厨师用来实现其目标的特定认知架构** 。## 3.2 Agent 推理框架跟以上厨师类似，Agent 也可以使用认知架构处理信息、做出决策，并根据前一轮的输出调整下一个行动，如此循环迭代来实现其最终目标。* 在 Agent 中，认知架构的核心是编排层，负责维护记忆、状态、推理和规划  （memory, state, reasoning and planning）。* 它使用快速发展的提示词工程及相关框架  （prompt engineering and associated frameworks）来指导推理和规划  ，使 Agent 能够更有效地与环境互动并完成任务。在写作本文时，有下面几种流行的推理框架和推理技术。### 3.2.1 ReAct为语言模型提供了一个思考过程策略。已经证明 ReAct 优于几个 SOTA 基线，提高了 LLM 的人机交互性和可信度。### 3.2.2 Chain-of-Thought (CoT)通过中间步骤实现推理能力。CoT 有各种子技术，包括自我一致性、主动提示和多模态 CoT，适合不同的场景。### 3.2.3 Tree-of-Thoughts (ToT)非常适合探索或战略前瞻任务。概括了链式思考提示，并允许模型探索各种思考链，作为使用语言模型解决问题的中间步骤。## 3.3 ReAct 例子Agent 可以使用以上一种或多种推理技术，给特定的用户请求确定下一个最佳行动。 例如，使用 ReAct 的例子，* 用户向 Agent 发送查询。 * Agent 开始 ReAct sequence。 * Agent 提示模型，要求其生成下一个 ReAct 步骤及其相应的输出：  * 问题：提示词 + 用户输入的问题 * 思考：模型的想法：下一步应该做什么 * 行动：模型的决策：下一步要采取什么行动。这里就是可以引入工具的地方， 例如，行动可以是 [Flights, Search, Code, None]* 行动的输入：模型决定是否要向工具提供输入，如果要提供，还要确定提供哪些输入 * 观察：行动/行动输入序列的结果。根据需要，这个思考/行动/行动输入/观察（thought / action / action input / observation* 最终答案：模型返回对原始用户查询的最终答案。"></sub>

#### **2. Chain-of-Thought (CoT)**
- **核心能力**：通过中间推理步骤实现复杂推理
- **变体技术**：
  - 自我一致性（Self-Consistency）
  - 主动提示（Active Prompting）
  - 多模态CoT<sub index="2" url="https://arthurchiao.art/blog/ai-agent-white-paper-zh/" title="[译] AI Agent（智能体）技术白皮书（Google，2024）" snippet="例如，结合用户信息和获取天气数据的 tool，Agent 可以为用户提供旅行建议。有了工具，Agent 可以访问和处理现实世界的信息，这使它们能够支撑更专业的系统，如检索增强生成（RAG），显著扩展了 Agent 的能力。### 2.3.3 编排层（orchestration）编排层描述了一个**循环** 过程：Agent 如何接收信息，如何进行内部推理，如何使用推理来结果来指导其下一步行动或决策。* 一般来说，这个循环会持续进行，直到 Agent 达到其目标或触发停止条件。 * 编排层的复杂性跟 Agent 及其执行的任务直接相关，可能差异很大。 例如，一些编排就是简单的计算和决策规则，而其他的可能包含链式逻辑、额外的机器学习算法或其他概率推理技术。 我们将在认知架构部分更详细地讨论 Agent 编排层的详细实现。## 2.4 Agent 与 model 的区别为了更清楚地理解 Agent 和模型之间的区别，这里整理个表格，|  模型   |                      Agent                       |                                               ||-------|--------------------------------------------------|-----------------------------------------------|| 知识范围  | 知识仅限于其 训练数据。                                     | 通过工具连接外部系统，能够在模型自带的知识之外，实时、动态 扩展知识。           || 状态与记忆 | 无状态，每次推理都跟上一次没关系，除非在外部给模型加上会话历史或上下文管理能力。         | 有状态，自动管理会话历史，根据编排自主决策进行多轮推理。                  || 原生工具  | 无。                                               | 有，自带工具和对工具的支持能力。                              || 原生逻辑层 | 无。需要借助提示词工程或使用推理框架（CoT、ReAct 等）来形成复杂提示，指导模型进行预测。 | 有，原生认知架构，内置 CoT、ReAct 等推理框架或 LangChain 等编排框架。 |# 3 认知架构：Agent 是如何工作的## 3.1 类比：厨师做菜想象厨房中一群忙碌的厨师。他们的职责是根据顾客的菜单，为顾客烹制相应的菜品。这就涉及到我们前面提到的**&ldquo;规划 &mdash;&mdash; 执行 &mdash;&mdash; 调整&rdquo;** 循环。具体来说，厨师们需要执行以下步骤，* 收集信息（输入）：顾客点的菜，后厨现有的食材等等； * 推理（思考）：根据收集到的信息，判断可以做哪些菜； * 做菜（行动）：包括切菜、加调料、烹炒等等。 在以上每个阶段，厨师都根据需要进行调整 &mdash;&mdash; 例如某些食材不够用了，或者顾客反馈好吃或难吃了 &mdash;&mdash; 进而不断完善他们的计划。这个**信息接收、规划、执行和调整** （information intake, planning,executing, and adjusting）的循环描述的就是一个**厨师用来实现其目标的特定认知架构** 。## 3.2 Agent 推理框架跟以上厨师类似，Agent 也可以使用认知架构处理信息、做出决策，并根据前一轮的输出调整下一个行动，如此循环迭代来实现其最终目标。* 在 Agent 中，认知架构的核心是编排层，负责维护记忆、状态、推理和规划  （memory, state, reasoning and planning）。* 它使用快速发展的提示词工程及相关框架  （prompt engineering and associated frameworks）来指导推理和规划  ，使 Agent 能够更有效地与环境互动并完成任务。在写作本文时，有下面几种流行的推理框架和推理技术。### 3.2.1 ReAct为语言模型提供了一个思考过程策略。已经证明 ReAct 优于几个 SOTA 基线，提高了 LLM 的人机交互性和可信度。### 3.2.2 Chain-of-Thought (CoT)通过中间步骤实现推理能力。CoT 有各种子技术，包括自我一致性、主动提示和多模态 CoT，适合不同的场景。### 3.2.3 Tree-of-Thoughts (ToT)非常适合探索或战略前瞻任务。概括了链式思考提示，并允许模型探索各种思考链，作为使用语言模型解决问题的中间步骤。## 3.3 ReAct 例子Agent 可以使用以上一种或多种推理技术，给特定的用户请求确定下一个最佳行动。 例如，使用 ReAct 的例子，* 用户向 Agent 发送查询。 * Agent 开始 ReAct sequence。 * Agent 提示模型，要求其生成下一个 ReAct 步骤及其相应的输出：  * 问题：提示词 + 用户输入的问题 * 思考：模型的想法：下一步应该做什么 * 行动：模型的决策：下一步要采取什么行动。这里就是可以引入工具的地方， 例如，行动可以是 [Flights, Search, Code, None]* 行动的输入：模型决定是否要向工具提供输入，如果要提供，还要确定提供哪些输入 * 观察：行动/行动输入序列的结果。根据需要，这个思考/行动/行动输入/观察（thought / action / action input / observation* 最终答案：模型返回对原始用户查询的最终答案。"></sub>

#### **3. Tree-of-Thoughts (ToT)**
- **适用场景**：探索性任务、战略规划
- **特点**：允许模型探索多条思考链路<sub index="2" url="https://arthurchiao.art/blog/ai-agent-white-paper-zh/" title="[译] AI Agent（智能体）技术白皮书（Google，2024）" snippet="例如，结合用户信息和获取天气数据的 tool，Agent 可以为用户提供旅行建议。有了工具，Agent 可以访问和处理现实世界的信息，这使它们能够支撑更专业的系统，如检索增强生成（RAG），显著扩展了 Agent 的能力。### 2.3.3 编排层（orchestration）编排层描述了一个**循环** 过程：Agent 如何接收信息，如何进行内部推理，如何使用推理来结果来指导其下一步行动或决策。* 一般来说，这个循环会持续进行，直到 Agent 达到其目标或触发停止条件。 * 编排层的复杂性跟 Agent 及其执行的任务直接相关，可能差异很大。 例如，一些编排就是简单的计算和决策规则，而其他的可能包含链式逻辑、额外的机器学习算法或其他概率推理技术。 我们将在认知架构部分更详细地讨论 Agent 编排层的详细实现。## 2.4 Agent 与 model 的区别为了更清楚地理解 Agent 和模型之间的区别，这里整理个表格，|  模型   |                      Agent                       |                                               ||-------|--------------------------------------------------|-----------------------------------------------|| 知识范围  | 知识仅限于其 训练数据。                                     | 通过工具连接外部系统，能够在模型自带的知识之外，实时、动态 扩展知识。           || 状态与记忆 | 无状态，每次推理都跟上一次没关系，除非在外部给模型加上会话历史或上下文管理能力。         | 有状态，自动管理会话历史，根据编排自主决策进行多轮推理。                  || 原生工具  | 无。                                               | 有，自带工具和对工具的支持能力。                              || 原生逻辑层 | 无。需要借助提示词工程或使用推理框架（CoT、ReAct 等）来形成复杂提示，指导模型进行预测。 | 有，原生认知架构，内置 CoT、ReAct 等推理框架或 LangChain 等编排框架。 |# 3 认知架构：Agent 是如何工作的## 3.1 类比：厨师做菜想象厨房中一群忙碌的厨师。他们的职责是根据顾客的菜单，为顾客烹制相应的菜品。这就涉及到我们前面提到的**&ldquo;规划 &mdash;&mdash; 执行 &mdash;&mdash; 调整&rdquo;** 循环。具体来说，厨师们需要执行以下步骤，* 收集信息（输入）：顾客点的菜，后厨现有的食材等等； * 推理（思考）：根据收集到的信息，判断可以做哪些菜； * 做菜（行动）：包括切菜、加调料、烹炒等等。 在以上每个阶段，厨师都根据需要进行调整 &mdash;&mdash; 例如某些食材不够用了，或者顾客反馈好吃或难吃了 &mdash;&mdash; 进而不断完善他们的计划。这个**信息接收、规划、执行和调整** （information intake, planning,executing, and adjusting）的循环描述的就是一个**厨师用来实现其目标的特定认知架构** 。## 3.2 Agent 推理框架跟以上厨师类似，Agent 也可以使用认知架构处理信息、做出决策，并根据前一轮的输出调整下一个行动，如此循环迭代来实现其最终目标。* 在 Agent 中，认知架构的核心是编排层，负责维护记忆、状态、推理和规划  （memory, state, reasoning and planning）。* 它使用快速发展的提示词工程及相关框架  （prompt engineering and associated frameworks）来指导推理和规划  ，使 Agent 能够更有效地与环境互动并完成任务。在写作本文时，有下面几种流行的推理框架和推理技术。### 3.2.1 ReAct为语言模型提供了一个思考过程策略。已经证明 ReAct 优于几个 SOTA 基线，提高了 LLM 的人机交互性和可信度。### 3.2.2 Chain-of-Thought (CoT)通过中间步骤实现推理能力。CoT 有各种子技术，包括自我一致性、主动提示和多模态 CoT，适合不同的场景。### 3.2.3 Tree-of-Thoughts (ToT)非常适合探索或战略前瞻任务。概括了链式思考提示，并允许模型探索各种思考链，作为使用语言模型解决问题的中间步骤。## 3.3 ReAct 例子Agent 可以使用以上一种或多种推理技术，给特定的用户请求确定下一个最佳行动。 例如，使用 ReAct 的例子，* 用户向 Agent 发送查询。 * Agent 开始 ReAct sequence。 * Agent 提示模型，要求其生成下一个 ReAct 步骤及其相应的输出：  * 问题：提示词 + 用户输入的问题 * 思考：模型的想法：下一步应该做什么 * 行动：模型的决策：下一步要采取什么行动。这里就是可以引入工具的地方， 例如，行动可以是 [Flights, Search, Code, None]* 行动的输入：模型决定是否要向工具提供输入，如果要提供，还要确定提供哪些输入 * 观察：行动/行动输入序列的结果。根据需要，这个思考/行动/行动输入/观察（thought / action / action input / observation* 最终答案：模型返回对原始用户查询的最终答案。"></sub>

## 📚 前沿研究论文集

### **Agent进化与自适应论文库**<sub index="3" url="https://github.com/masamasa59/ai-agent-papers" title="A collection of AI Agents papers (Updated biweekly)" snippet="* &quot;Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning&quot;  [paper]* &quot;LIVE-SWE-AGENT: Can Software Engineering Agents Self-Evolve on the Fly?&quot;  [paper]* &quot;AgentEvolver: Towards Efficient Self-Evolving Agent System&quot;  [paper]* 📖 &quot;Scaling Environments for LLM Agents in the Era of Learning from Interaction: A Survey&quot;  [paper]* &quot;Real-Time Reasoning Agents in Evolving Environments&quot;  [paper]* &quot;FLEX: Continuous Agent Evolution via Forward Learning from Experience&quot;  [paper]* &quot;Evo-Memory: Benchmarking LLM Agent Test-time Learning with Self-Evolving Memory&quot;  [paper]* &quot;A2Flow: Automating Agentic Workflow Generation via Self-Adaptive Abstraction Operators&quot;  [paper]* &quot;Evolution without an Oracle: Driving Effective Evolution with LLM Judges&quot;  [paper]* &quot;GigaEvo: An Open Source Optimization Framework Powered By LLMs And Evolution Algorithms&quot;  [paper]* &quot;OmniScientist: Toward a Co-evolving Ecosystem of Human and AI Scientists&quot;  [paper]* **&quot;ThetaEvolve: Test-time Learning on Open Problems&quot;** [paper]* **&quot;Improving Language Agents through BREW&quot;** [paper]* &quot;General Agentic Memory Via Deep Research&quot;  [paper]* **&quot;Episodic Memory in Agentic Frameworks: Suggesting Next Tasks&quot;** [paper]* **&quot;Simulating Environments with Reasoning Models for Agent Training&quot;** [paper]* &quot;VisPlay: Self-Evolving Vision-Language Models from Images&quot;  [paper]* &quot;Agent0: Unleashing Self-Evolving Agents from Zero Data via Tool-Integrated Reasoning&quot;  [paper]* &quot;Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning&quot;  [paper]* **&quot;Scaling Agent Learning via Experience Synthesis&quot;** [paper]* **&quot;ACON: Optimizing Context Compression for Long-horizon LLM Agents&quot;** [paper]"></sub>
**GitHub仓库**：https://github.com/masamasa59/ai-agent-papers

**核心研究方向**：

#### **1. 强化学习类**
- **Agent-R1**: 端到端强化学习训练强大的LLM Agent
- **BREW**: 通过强化学习改进语言Agent

#### **2. 自进化系统**
- **AgentEvolver**: 高效自进化Agent系统
- **FLEX**: 通过前向经验学习实现持续Agent进化
- **Agent0**: 零数据启动的自进化Agent

#### **3. 记忆与学习**
- **Evo-Memory**: 带自进化记忆的LLM Agent基准测试
- **Episodic Memory**: Agent框架中的情景记忆
- **General Agentic Memory**: 通过深度研究实现通用记忆

#### **4. 多Agent系统**
- **A2Flow**: 自动化Agent工作流生成
- **OmniScientist**: 人类与AI科学家共同进化生态系统

#### **5. 环境交互**
- **Scaling Environments**: 交互学习时代的LLM Agent环境扩展
- **Real-Time Reasoning Agents**: 在演化环境中的实时推理
- **Simulating Environments**: 使用推理模型模拟环境进行Agent训练

## 🔧 实践框架与工具

### **推荐学习顺序**

**入门阶段（1-2周）**：
1. 阅读C3 AI白皮书了解Agent基本概念<sub index="1" url="https://c3.ai/white-paper-ai-agents-for-enterprise-grade-agentic-process-automation/" title="White Paper: AI Agents for Enterprise-Grade ..." snippet="# White Paper: AI Agents for Enterprise-Grade Agentic Process AutomationAI agents represent a paradigm shift, moving beyond simple rule-based task execution to complex, goal-oriented decision-making. AI agents can receive an abstract goal and input, formulate a plan to achieve that goal, and then use a set of &ldquo;tools&rdquo; to execute that plan. This white paper seeks to define AI agents, explain the critical components of an AI agent, and present a framework for the successful, timely, and cost-effective implementation of AI agents in the enterprise. We additionally address the emerging new concept of C3 AI Agentic Process Automation with advanced AI agent-assisted reasoning to unlock outsized economic value at scale. C3 AI has invested deeply in building an agentic architecture purpose-built for the complexity of enterprise environments.In this white paper, you will learn about:* AI agents and how they work * Requirements for AI agents for high-value, enterprise use cases * Transforming enterprise work with agentic process automation * Four case studies from C3 AI highlighting AI agents and agentic process automation in enterprise deployments "></sub>
2. 学习Agent三层架构<sub index="2" url="https://arthurchiao.art/blog/ai-agent-white-paper-zh/" title="[译] AI Agent（智能体）技术白皮书（Google，2024）" snippet="例如，结合用户信息和获取天气数据的 tool，Agent 可以为用户提供旅行建议。有了工具，Agent 可以访问和处理现实世界的信息，这使它们能够支撑更专业的系统，如检索增强生成（RAG），显著扩展了 Agent 的能力。### 2.3.3 编排层（orchestration）编排层描述了一个**循环** 过程：Agent 如何接收信息，如何进行内部推理，如何使用推理来结果来指导其下一步行动或决策。* 一般来说，这个循环会持续进行，直到 Agent 达到其目标或触发停止条件。 * 编排层的复杂性跟 Agent 及其执行的任务直接相关，可能差异很大。 例如，一些编排就是简单的计算和决策规则，而其他的可能包含链式逻辑、额外的机器学习算法或其他概率推理技术。 我们将在认知架构部分更详细地讨论 Agent 编排层的详细实现。## 2.4 Agent 与 model 的区别为了更清楚地理解 Agent 和模型之间的区别，这里整理个表格，|  模型   |                      Agent                       |                                               ||-------|--------------------------------------------------|-----------------------------------------------|| 知识范围  | 知识仅限于其 训练数据。                                     | 通过工具连接外部系统，能够在模型自带的知识之外，实时、动态 扩展知识。           || 状态与记忆 | 无状态，每次推理都跟上一次没关系，除非在外部给模型加上会话历史或上下文管理能力。         | 有状态，自动管理会话历史，根据编排自主决策进行多轮推理。                  || 原生工具  | 无。                                               | 有，自带工具和对工具的支持能力。                              || 原生逻辑层 | 无。需要借助提示词工程或使用推理框架（CoT、ReAct 等）来形成复杂提示，指导模型进行预测。 | 有，原生认知架构，内置 CoT、ReAct 等推理框架或 LangChain 等编排框架。 |# 3 认知架构：Agent 是如何工作的## 3.1 类比：厨师做菜想象厨房中一群忙碌的厨师。他们的职责是根据顾客的菜单，为顾客烹制相应的菜品。这就涉及到我们前面提到的**&ldquo;规划 &mdash;&mdash; 执行 &mdash;&mdash; 调整&rdquo;** 循环。具体来说，厨师们需要执行以下步骤，* 收集信息（输入）：顾客点的菜，后厨现有的食材等等； * 推理（思考）：根据收集到的信息，判断可以做哪些菜； * 做菜（行动）：包括切菜、加调料、烹炒等等。 在以上每个阶段，厨师都根据需要进行调整 &mdash;&mdash; 例如某些食材不够用了，或者顾客反馈好吃或难吃了 &mdash;&mdash; 进而不断完善他们的计划。这个**信息接收、规划、执行和调整** （information intake, planning,executing, and adjusting）的循环描述的就是一个**厨师用来实现其目标的特定认知架构** 。## 3.2 Agent 推理框架跟以上厨师类似，Agent 也可以使用认知架构处理信息、做出决策，并根据前一轮的输出调整下一个行动，如此循环迭代来实现其最终目标。* 在 Agent 中，认知架构的核心是编排层，负责维护记忆、状态、推理和规划  （memory, state, reasoning and planning）。* 它使用快速发展的提示词工程及相关框架  （prompt engineering and associated frameworks）来指导推理和规划  ，使 Agent 能够更有效地与环境互动并完成任务。在写作本文时，有下面几种流行的推理框架和推理技术。### 3.2.1 ReAct为语言模型提供了一个思考过程策略。已经证明 ReAct 优于几个 SOTA 基线，提高了 LLM 的人机交互性和可信度。### 3.2.2 Chain-of-Thought (CoT)通过中间步骤实现推理能力。CoT 有各种子技术，包括自我一致性、主动提示和多模态 CoT，适合不同的场景。### 3.2.3 Tree-of-Thoughts (ToT)非常适合探索或战略前瞻任务。概括了链式思考提示，并允许模型探索各种思考链，作为使用语言模型解决问题的中间步骤。## 3.3 ReAct 例子Agent 可以使用以上一种或多种推理技术，给特定的用户请求确定下一个最佳行动。 例如，使用 ReAct 的例子，* 用户向 Agent 发送查询。 * Agent 开始 ReAct sequence。 * Agent 提示模型，要求其生成下一个 ReAct 步骤及其相应的输出：  * 问题：提示词 + 用户输入的问题 * 思考：模型的想法：下一步应该做什么 * 行动：模型的决策：下一步要采取什么行动。这里就是可以引入工具的地方， 例如，行动可以是 [Flights, Search, Code, None]* 行动的输入：模型决定是否要向工具提供输入，如果要提供，还要确定提供哪些输入 * 观察：行动/行动输入序列的结果。根据需要，这个思考/行动/行动输入/观察（thought / action / action input / observation* 最终答案：模型返回对原始用户查询的最终答案。"></sub>
3. 理解ReAct框架工作原理<sub index="2" url="https://arthurchiao.art/blog/ai-agent-white-paper-zh/" title="[译] AI Agent（智能体）技术白皮书（Google，2024）" snippet="例如，结合用户信息和获取天气数据的 tool，Agent 可以为用户提供旅行建议。有了工具，Agent 可以访问和处理现实世界的信息，这使它们能够支撑更专业的系统，如检索增强生成（RAG），显著扩展了 Agent 的能力。### 2.3.3 编排层（orchestration）编排层描述了一个**循环** 过程：Agent 如何接收信息，如何进行内部推理，如何使用推理来结果来指导其下一步行动或决策。* 一般来说，这个循环会持续进行，直到 Agent 达到其目标或触发停止条件。 * 编排层的复杂性跟 Agent 及其执行的任务直接相关，可能差异很大。 例如，一些编排就是简单的计算和决策规则，而其他的可能包含链式逻辑、额外的机器学习算法或其他概率推理技术。 我们将在认知架构部分更详细地讨论 Agent 编排层的详细实现。## 2.4 Agent 与 model 的区别为了更清楚地理解 Agent 和模型之间的区别，这里整理个表格，|  模型   |                      Agent                       |                                               ||-------|--------------------------------------------------|-----------------------------------------------|| 知识范围  | 知识仅限于其 训练数据。                                     | 通过工具连接外部系统，能够在模型自带的知识之外，实时、动态 扩展知识。           || 状态与记忆 | 无状态，每次推理都跟上一次没关系，除非在外部给模型加上会话历史或上下文管理能力。         | 有状态，自动管理会话历史，根据编排自主决策进行多轮推理。                  || 原生工具  | 无。                                               | 有，自带工具和对工具的支持能力。                              || 原生逻辑层 | 无。需要借助提示词工程或使用推理框架（CoT、ReAct 等）来形成复杂提示，指导模型进行预测。 | 有，原生认知架构，内置 CoT、ReAct 等推理框架或 LangChain 等编排框架。 |# 3 认知架构：Agent 是如何工作的## 3.1 类比：厨师做菜想象厨房中一群忙碌的厨师。他们的职责是根据顾客的菜单，为顾客烹制相应的菜品。这就涉及到我们前面提到的**&ldquo;规划 &mdash;&mdash; 执行 &mdash;&mdash; 调整&rdquo;** 循环。具体来说，厨师们需要执行以下步骤，* 收集信息（输入）：顾客点的菜，后厨现有的食材等等； * 推理（思考）：根据收集到的信息，判断可以做哪些菜； * 做菜（行动）：包括切菜、加调料、烹炒等等。 在以上每个阶段，厨师都根据需要进行调整 &mdash;&mdash; 例如某些食材不够用了，或者顾客反馈好吃或难吃了 &mdash;&mdash; 进而不断完善他们的计划。这个**信息接收、规划、执行和调整** （information intake, planning,executing, and adjusting）的循环描述的就是一个**厨师用来实现其目标的特定认知架构** 。## 3.2 Agent 推理框架跟以上厨师类似，Agent 也可以使用认知架构处理信息、做出决策，并根据前一轮的输出调整下一个行动，如此循环迭代来实现其最终目标。* 在 Agent 中，认知架构的核心是编排层，负责维护记忆、状态、推理和规划  （memory, state, reasoning and planning）。* 它使用快速发展的提示词工程及相关框架  （prompt engineering and associated frameworks）来指导推理和规划  ，使 Agent 能够更有效地与环境互动并完成任务。在写作本文时，有下面几种流行的推理框架和推理技术。### 3.2.1 ReAct为语言模型提供了一个思考过程策略。已经证明 ReAct 优于几个 SOTA 基线，提高了 LLM 的人机交互性和可信度。### 3.2.2 Chain-of-Thought (CoT)通过中间步骤实现推理能力。CoT 有各种子技术，包括自我一致性、主动提示和多模态 CoT，适合不同的场景。### 3.2.3 Tree-of-Thoughts (ToT)非常适合探索或战略前瞻任务。概括了链式思考提示，并允许模型探索各种思考链，作为使用语言模型解决问题的中间步骤。## 3.3 ReAct 例子Agent 可以使用以上一种或多种推理技术，给特定的用户请求确定下一个最佳行动。 例如，使用 ReAct 的例子，* 用户向 Agent 发送查询。 * Agent 开始 ReAct sequence。 * Agent 提示模型，要求其生成下一个 ReAct 步骤及其相应的输出：  * 问题：提示词 + 用户输入的问题 * 思考：模型的想法：下一步应该做什么 * 行动：模型的决策：下一步要采取什么行动。这里就是可以引入工具的地方， 例如，行动可以是 [Flights, Search, Code, None]* 行动的输入：模型决定是否要向工具提供输入，如果要提供，还要确定提供哪些输入 * 观察：行动/行动输入序列的结果。根据需要，这个思考/行动/行动输入/观察（thought / action / action input / observation* 最终答案：模型返回对原始用户查询的最终答案。"></sub>

**进阶阶段（2-4周）**：
1. 深入研究CoT和ToT推理技术<sub index="2" url="https://arthurchiao.art/blog/ai-agent-white-paper-zh/" title="[译] AI Agent（智能体）技术白皮书（Google，2024）" snippet="例如，结合用户信息和获取天气数据的 tool，Agent 可以为用户提供旅行建议。有了工具，Agent 可以访问和处理现实世界的信息，这使它们能够支撑更专业的系统，如检索增强生成（RAG），显著扩展了 Agent 的能力。### 2.3.3 编排层（orchestration）编排层描述了一个**循环** 过程：Agent 如何接收信息，如何进行内部推理，如何使用推理来结果来指导其下一步行动或决策。* 一般来说，这个循环会持续进行，直到 Agent 达到其目标或触发停止条件。 * 编排层的复杂性跟 Agent 及其执行的任务直接相关，可能差异很大。 例如，一些编排就是简单的计算和决策规则，而其他的可能包含链式逻辑、额外的机器学习算法或其他概率推理技术。 我们将在认知架构部分更详细地讨论 Agent 编排层的详细实现。## 2.4 Agent 与 model 的区别为了更清楚地理解 Agent 和模型之间的区别，这里整理个表格，|  模型   |                      Agent                       |                                               ||-------|--------------------------------------------------|-----------------------------------------------|| 知识范围  | 知识仅限于其 训练数据。                                     | 通过工具连接外部系统，能够在模型自带的知识之外，实时、动态 扩展知识。           || 状态与记忆 | 无状态，每次推理都跟上一次没关系，除非在外部给模型加上会话历史或上下文管理能力。         | 有状态，自动管理会话历史，根据编排自主决策进行多轮推理。                  || 原生工具  | 无。                                               | 有，自带工具和对工具的支持能力。                              || 原生逻辑层 | 无。需要借助提示词工程或使用推理框架（CoT、ReAct 等）来形成复杂提示，指导模型进行预测。 | 有，原生认知架构，内置 CoT、ReAct 等推理框架或 LangChain 等编排框架。 |# 3 认知架构：Agent 是如何工作的## 3.1 类比：厨师做菜想象厨房中一群忙碌的厨师。他们的职责是根据顾客的菜单，为顾客烹制相应的菜品。这就涉及到我们前面提到的**&ldquo;规划 &mdash;&mdash; 执行 &mdash;&mdash; 调整&rdquo;** 循环。具体来说，厨师们需要执行以下步骤，* 收集信息（输入）：顾客点的菜，后厨现有的食材等等； * 推理（思考）：根据收集到的信息，判断可以做哪些菜； * 做菜（行动）：包括切菜、加调料、烹炒等等。 在以上每个阶段，厨师都根据需要进行调整 &mdash;&mdash; 例如某些食材不够用了，或者顾客反馈好吃或难吃了 &mdash;&mdash; 进而不断完善他们的计划。这个**信息接收、规划、执行和调整** （information intake, planning,executing, and adjusting）的循环描述的就是一个**厨师用来实现其目标的特定认知架构** 。## 3.2 Agent 推理框架跟以上厨师类似，Agent 也可以使用认知架构处理信息、做出决策，并根据前一轮的输出调整下一个行动，如此循环迭代来实现其最终目标。* 在 Agent 中，认知架构的核心是编排层，负责维护记忆、状态、推理和规划  （memory, state, reasoning and planning）。* 它使用快速发展的提示词工程及相关框架  （prompt engineering and associated frameworks）来指导推理和规划  ，使 Agent 能够更有效地与环境互动并完成任务。在写作本文时，有下面几种流行的推理框架和推理技术。### 3.2.1 ReAct为语言模型提供了一个思考过程策略。已经证明 ReAct 优于几个 SOTA 基线，提高了 LLM 的人机交互性和可信度。### 3.2.2 Chain-of-Thought (CoT)通过中间步骤实现推理能力。CoT 有各种子技术，包括自我一致性、主动提示和多模态 CoT，适合不同的场景。### 3.2.3 Tree-of-Thoughts (ToT)非常适合探索或战略前瞻任务。概括了链式思考提示，并允许模型探索各种思考链，作为使用语言模型解决问题的中间步骤。## 3.3 ReAct 例子Agent 可以使用以上一种或多种推理技术，给特定的用户请求确定下一个最佳行动。 例如，使用 ReAct 的例子，* 用户向 Agent 发送查询。 * Agent 开始 ReAct sequence。 * Agent 提示模型，要求其生成下一个 ReAct 步骤及其相应的输出：  * 问题：提示词 + 用户输入的问题 * 思考：模型的想法：下一步应该做什么 * 行动：模型的决策：下一步要采取什么行动。这里就是可以引入工具的地方， 例如，行动可以是 [Flights, Search, Code, None]* 行动的输入：模型决定是否要向工具提供输入，如果要提供，还要确定提供哪些输入 * 观察：行动/行动输入序列的结果。根据需要，这个思考/行动/行动输入/观察（thought / action / action input / observation* 最终答案：模型返回对原始用户查询的最终答案。"></sub>
2. 阅读Kaggle白皮书理解工具使用<sub index="4" url="https://www.kaggle.com/whitepaper-agents" title="Agents" snippet="Humans are fantastic at messy pattern recognition tasks. However, they often rely on tools - like books, Google Search, or a calculator - to supplement their prior knowledge before arriving at a conclusion. Just like humans, Generative AI models can be trained to use tools to access real-time information or suggest a real-world action. For example, a model can leverage a database retrieval tool to access specific information, like a customer's purchase history, so it can generate tailored shopping recommendations. Alternatively, based on a user's query, a model can make various API calls to send an email response to a colleague or complete a financial transaction on your behalf. To do so, the model must not only have access to a set of external tools, it needs the ability to plan and execute any task in a self-directed fashion. This combination of reasoning, logic, and access to external information that are all connected to a Generative AI model invokes the concept of an agent, or a program that extends beyond the standalone capabilities of a Generative AI model. This whitepaper dives into all these and associated aspects in more detail.Authors: Julia Wiesinger, Patrick Marlow and Vladimir VuskovicIntroductionRead the whitepaper below"></sub>
3. 实践ReAct论文的代码实现<sub index="5" url="https://arxiv.org/abs/2210.03629" title="Synergizing Reasoning and Acting in Language Models" snippet=""></sub>

**高级阶段（持续学习）**：
1. 跟踪GitHub论文库的最新研究<sub index="3" url="https://github.com/masamasa59/ai-agent-papers" title="A collection of AI Agents papers (Updated biweekly)" snippet="* &quot;Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning&quot;  [paper]* &quot;LIVE-SWE-AGENT: Can Software Engineering Agents Self-Evolve on the Fly?&quot;  [paper]* &quot;AgentEvolver: Towards Efficient Self-Evolving Agent System&quot;  [paper]* 📖 &quot;Scaling Environments for LLM Agents in the Era of Learning from Interaction: A Survey&quot;  [paper]* &quot;Real-Time Reasoning Agents in Evolving Environments&quot;  [paper]* &quot;FLEX: Continuous Agent Evolution via Forward Learning from Experience&quot;  [paper]* &quot;Evo-Memory: Benchmarking LLM Agent Test-time Learning with Self-Evolving Memory&quot;  [paper]* &quot;A2Flow: Automating Agentic Workflow Generation via Self-Adaptive Abstraction Operators&quot;  [paper]* &quot;Evolution without an Oracle: Driving Effective Evolution with LLM Judges&quot;  [paper]* &quot;GigaEvo: An Open Source Optimization Framework Powered By LLMs And Evolution Algorithms&quot;  [paper]* &quot;OmniScientist: Toward a Co-evolving Ecosystem of Human and AI Scientists&quot;  [paper]* **&quot;ThetaEvolve: Test-time Learning on Open Problems&quot;** [paper]* **&quot;Improving Language Agents through BREW&quot;** [paper]* &quot;General Agentic Memory Via Deep Research&quot;  [paper]* **&quot;Episodic Memory in Agentic Frameworks: Suggesting Next Tasks&quot;** [paper]* **&quot;Simulating Environments with Reasoning Models for Agent Training&quot;** [paper]* &quot;VisPlay: Self-Evolving Vision-Language Models from Images&quot;  [paper]* &quot;Agent0: Unleashing Self-Evolving Agents from Zero Data via Tool-Integrated Reasoning&quot;  [paper]* &quot;Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning&quot;  [paper]* **&quot;Scaling Agent Learning via Experience Synthesis&quot;** [paper]* **&quot;ACON: Optimizing Context Compression for Long-horizon LLM Agents&quot;** [paper]"></sub>
2. 关注自进化Agent和记忆系统
3. 研究Multi-Agent协作机制

## 💡 学习建议

1. **从架构理解开始**：先掌握Agent的三层架构，理解模型、工具、编排的关系
2. **重点学习ReAct**：这是当前最实用的推理框架
3. **关注企业应用**：C3 AI白皮书提供了真实案例参考<sub index="1" url="https://c3.ai/white-paper-ai-agents-for-enterprise-grade-agentic-process-automation/" title="White Paper: AI Agents for Enterprise-Grade ..." snippet="# White Paper: AI Agents for Enterprise-Grade Agentic Process AutomationAI agents represent a paradigm shift, moving beyond simple rule-based task execution to complex, goal-oriented decision-making. AI agents can receive an abstract goal and input, formulate a plan to achieve that goal, and then use a set of &ldquo;tools&rdquo; to execute that plan. This white paper seeks to define AI agents, explain the critical components of an AI agent, and present a framework for the successful, timely, and cost-effective implementation of AI agents in the enterprise. We additionally address the emerging new concept of C3 AI Agentic Process Automation with advanced AI agent-assisted reasoning to unlock outsized economic value at scale. C3 AI has invested deeply in building an agentic architecture purpose-built for the complexity of enterprise environments.In this white paper, you will learn about:* AI agents and how they work * Requirements for AI agents for high-value, enterprise use cases * Transforming enterprise work with agentic process automation * Four case studies from C3 AI highlighting AI agents and agentic process automation in enterprise deployments "></sub>
4. **追踪前沿研究**：定期查看GitHub论文库更新<sub index="3" url="https://github.com/masamasa59/ai-agent-papers" title="A collection of AI Agents papers (Updated biweekly)" snippet="* &quot;Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning&quot;  [paper]* &quot;LIVE-SWE-AGENT: Can Software Engineering Agents Self-Evolve on the Fly?&quot;  [paper]* &quot;AgentEvolver: Towards Efficient Self-Evolving Agent System&quot;  [paper]* 📖 &quot;Scaling Environments for LLM Agents in the Era of Learning from Interaction: A Survey&quot;  [paper]* &quot;Real-Time Reasoning Agents in Evolving Environments&quot;  [paper]* &quot;FLEX: Continuous Agent Evolution via Forward Learning from Experience&quot;  [paper]* &quot;Evo-Memory: Benchmarking LLM Agent Test-time Learning with Self-Evolving Memory&quot;  [paper]* &quot;A2Flow: Automating Agentic Workflow Generation via Self-Adaptive Abstraction Operators&quot;  [paper]* &quot;Evolution without an Oracle: Driving Effective Evolution with LLM Judges&quot;  [paper]* &quot;GigaEvo: An Open Source Optimization Framework Powered By LLMs And Evolution Algorithms&quot;  [paper]* &quot;OmniScientist: Toward a Co-evolving Ecosystem of Human and AI Scientists&quot;  [paper]* **&quot;ThetaEvolve: Test-time Learning on Open Problems&quot;** [paper]* **&quot;Improving Language Agents through BREW&quot;** [paper]* &quot;General Agentic Memory Via Deep Research&quot;  [paper]* **&quot;Episodic Memory in Agentic Frameworks: Suggesting Next Tasks&quot;** [paper]* **&quot;Simulating Environments with Reasoning Models for Agent Training&quot;** [paper]* &quot;VisPlay: Self-Evolving Vision-Language Models from Images&quot;  [paper]* &quot;Agent0: Unleashing Self-Evolving Agents from Zero Data via Tool-Integrated Reasoning&quot;  [paper]* &quot;Agent-R1: Training Powerful LLM Agents with End-to-End Reinforcement Learning&quot;  [paper]* **&quot;Scaling Agent Learning via Experience Synthesis&quot;** [paper]* **&quot;ACON: Optimizing Context Compression for Long-horizon LLM Agents&quot;** [paper]"></sub>

这些资源涵盖了从基础概念到前沿研究的完整知识体系，建议按照推荐的学习顺序逐步深入！
